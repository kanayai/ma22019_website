{
  "hash": "3e9b1f92892408a7ac3fa67f12be210f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analysis of the work by Charles Dickens\"\ndate: \"12/03/2025\"\n---\n\n\n\n## Loading packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(topicmodels)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_raw <- read.csv(\"data/dickens.csv\" )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Dickens_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                              text                title\n1             A TALE OF TWO CITIES A Tale of Two Cities\n2                                  A Tale of Two Cities\n3 A STORY OF THE FRENCH REVOLUTION A Tale of Two Cities\n4                                  A Tale of Two Cities\n5               By Charles Dickens A Tale of Two Cities\n6                                  A Tale of Two Cities\n```\n\n\n:::\n:::\n\n\n# Term frequency - inverse document frequency\n\n## Prepare the data {-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens <- Dickens_raw %>%\n  unnest_tokens( word, text ) %>% \n  mutate( word = gsub( \"_\", \"\", word ) )\n```\n:::\n\n\n## Calculate tf-idf with stop words kept in the analysis {-}\n\nExtract counts for each word\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickensCount <- Dickens %>% count( title, word, sort=TRUE )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslice_head(DickensCount, n=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  title word    n\n1          Oliver Twist  the 9633\n2    Great Expectations  the 8145\n3  A Tale of Two Cities  the 8053\n4    Great Expectations  and 7098\n5    Great Expectations    i 6667\n6          Oliver Twist  and 5428\n7    Great Expectations   to 5157\n8  A Tale of Two Cities  and 4998\n9    Great Expectations   of 4438\n10   Great Expectations    a 4053\n```\n\n\n:::\n:::\n\n\nCalculate tf-idf using bind_tf_idf() from the tidytext package:\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_tf.idf <- DickensCount %>% \n  bind_tf_idf( word, title, n ) %>%\n  arrange( desc(tf_idf) ) %>%\n  mutate( idf=round(idf,2) )\nslice_head( Dickens_tf.idf, n=10 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  title     word   n          tf  idf      tf_idf\n1     A Christmas Carol  scrooge 327 0.011047671 1.39 0.015315323\n2          Oliver Twist   oliver 876 0.005397013 1.39 0.007481849\n3  A Tale of Two Cities    lorry 369 0.002664549 1.39 0.003693849\n4          Oliver Twist   bumble 397 0.002445907 1.39 0.003390747\n5          Oliver Twist    sikes 354 0.002180985 1.39 0.003023487\n6  A Tale of Two Cities  defarge 302 0.002180742 1.39 0.003023150\n7          Oliver Twist    fagin 309 0.001903741 1.39 0.002639145\n8    Great Expectations      pip 341 0.001803746 1.39 0.002500523\n9    Great Expectations havisham 318 0.001682086 1.39 0.002331866\n10   Great Expectations  herbert 313 0.001655638 1.39 0.002295201\n```\n\n\n:::\n:::\n\n\n\n## Calculate tf-idf with stop words removed {-}\n\nExtract counts for each word\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickensCount <- Dickens %>% \n  anti_join( stop_words, by=\"word\" ) %>%\n  count( title, word, sort=TRUE )\n```\n:::\n\n\nCalculate tf-idf using bind_tf_idf() from the tidytext package:\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_tf.idf <- DickensCount %>% \n  bind_tf_idf( word, title, n ) %>%\n  arrange( desc(tf_idf) ) %>%\n  mutate( idf=round(idf,2) )\nslice_head( Dickens_tf.idf, n=10 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  title     word   n          tf  idf      tf_idf\n1     A Christmas Carol  scrooge 327 0.032175539 1.39 0.044604768\n2          Oliver Twist   oliver 876 0.015483324 1.39 0.021464444\n3  A Tale of Two Cities    lorry 369 0.007949331 1.39 0.011020113\n4          Oliver Twist   bumble 397 0.007016986 1.39 0.009727608\n5  A Tale of Two Cities  defarge 302 0.006505957 1.39 0.009019171\n6          Oliver Twist    sikes 354 0.006256960 1.39 0.008673988\n7    Great Expectations      pip 341 0.006045027 1.39 0.008380188\n8    Great Expectations havisham 318 0.005637298 1.39 0.007814955\n9    Great Expectations  herbert 313 0.005548662 1.39 0.007692078\n10         Oliver Twist    fagin 309 0.005461583 1.39 0.007571362\n```\n\n\n:::\n:::\n\n\n\n# Topic modelling\n\n\n## Create identifier for each chapter {-}\n\n\n### Extract books and chapter {-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_chapters <- Dickens_raw %>%\n  filter( title %in% c( \"Great Expectations\",\"A Tale of Two Cities\" ) ) %>%\n  group_by( title ) %>%\n  mutate( chapter = cumsum( \n    str_detect( text, regex( \"^chapter \", ignore_case = TRUE ) ) \n  ) )\n```\n:::\n\n\n### Create identifier {-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_chapters <- Dickens_chapters %>%\n  filter( chapter > 0 ) %>%\n  unite( col=document, title, chapter )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Dickens_chapters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  text                                                                  document\n  <chr>                                                                 <chr>   \n1 \"CHAPTER I.\"                                                          A Tale …\n2 \"The Period\"                                                          A Tale …\n3 \"\"                                                                    A Tale …\n4 \"\"                                                                    A Tale …\n5 \"It was the best of times, it was the worst of times, it was the age… A Tale …\n6 \"wisdom, it was the age of foolishness, it was the epoch of belief, … A Tale …\n```\n\n\n:::\n:::\n\n\n\n## Construct the document term matrix {-}\n\nSplit text into individual words and remove stop words:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_chapters <- Dickens_chapters %>%\n  unnest_tokens( word, text ) %>%\n  mutate( word = gsub( \"_\", \"\", word ) ) %>%\n  anti_join( stop_words, by=\"word\" )\n```\n:::\n\n\nExtract counts for each word per chapter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_chapters <- Dickens_chapters %>% count( document, word, sort = TRUE )\n```\n:::\n\n\nConstruct the document term matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_dtm <- Dickens_chapters %>% cast_dtm( document, word, n )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_dtm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<<DocumentTermMatrix (documents: 104, terms: 13797)>>\nNon-/sparse entries: 65953/1368935\nSparsity           : 95%\nMaximal term length: 19\nWeighting          : term frequency (tf)\n```\n\n\n:::\n:::\n\n\n\n## Estimate Laten Dirichlet Allocation model {-} \n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_LDA <- LDA( Dickens_dtm, k=2, method = \"Gibbs\", control=list(seed=123) )\n```\n:::\n\n\n## Analysis of the estimates {-}\n\n### Make up of the chapters {-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDickens_topics <- tidy( Dickens_LDA , matrix = \"gamma\" ) \nDickens_topics %>% slice_head( n=4 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  document              topic gamma\n  <chr>                 <int> <dbl>\n1 Great Expectations_57     1 0.285\n2 Great Expectations_7      1 0.185\n3 Great Expectations_38     1 0.371\n4 Great Expectations_17     1 0.259\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDickens_topics %>%\n  separate( document, c(\"title\", \"chapter\"), sep=\"_\", convert=TRUE ) %>%\n  ggplot( aes( x=factor(topic), y=gamma ) ) + \n  facet_wrap( ~title ) + geom_boxplot() + \n  labs( x=\"Topic\", y=\"Proportion\" )\n```\n\n::: {.cell-output-display}\n![](analysis_of_the_work_by_charles_dickens_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=50%}\n:::\n:::\n\n\n### Make up of the topics {-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy( Dickens_LDA , matrix = \"beta\" ) %>%\n  group_by( topic ) %>%\n  slice_max( beta, n=3 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n# Groups:   topic [2]\n  topic term       beta\n  <int> <chr>     <dbl>\n1     1 lorry   0.00702\n2     1 hand    0.00643\n3     1 defarge 0.00574\n4     2 joe     0.0143 \n5     2 miss    0.00941\n6     2 don     0.00765\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy( Dickens_LDA , matrix = \"beta\" ) %>%\n  mutate( topic = case_when( topic==1 ~ \"Topic1\", topic==2 ~ \"Topic2\") ) %>%\n  pivot_wider( names_from = topic, values_from = beta, values_fill = 0 ) %>%\n  ggplot( aes(x=Topic1, y=Topic2) ) + geom_point() +  \n  geom_text( aes(label=term), check_overlap = TRUE, vjust=1 ) + \n  coord_trans( x=\"sqrt\", y=\"sqrt\" ) + theme_bw() +\n  labs( x=\"Term Frequency in Topic 1\", y=\"Term Frequency in Topic 2\" )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `coord_trans()` was deprecated in ggplot2 4.0.0.\nℹ Please use `coord_transform()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](analysis_of_the_work_by_charles_dickens_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=60%}\n:::\n:::\n\n",
    "supporting": [
      "analysis_of_the_work_by_charles_dickens_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}