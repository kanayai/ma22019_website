{
  "hash": "ff4fcd8e75be9508ff0a8d274f90c59b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MA22019 2025 - Solutions for Homework 6\"\nsubtitle: \"Mise en place\"\ncategories: [\"Homework\", \"Solutions\"]\n---\n\n\n\n\nYou may want to load the following packages before starting the exercise:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary( dplyr )\nlibrary( ggplot2 )\nlibrary( tidytext )\nlibrary( stringr )\nlibrary( tidyr )\nlibrary( topicmodels )\n```\n:::\n\n\nWhen working on a University PC, you have to first install the tidytext package and any dependencies using\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages( \"tidytext\", dependencies = TRUE )\n```\n:::\n\n\nFor the sentiment analysis you can load the sentiment lexicons using\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAFINN <- read.csv(\"data/AFINN Sentiment Lexicon.csv\")\nBing <- read.csv(\"data/Bing Sentiment Lexicon.csv\")\n```\n:::\n\n\n\n### **Homework Question - Sentiment Analysis vs Latent Dirichlet Allocation**\n\nSo far we have used sentiment analysis to explore whether a statement has a positive or negative emotional intent. The purpose of this exercise is to apply sentiment analysis to another data set and to explore whether Latent Dirichlet Allocation (LDA) is able to identify differences in the language used for positive and negative reviews. \n\nWe will be working with customer reviews for British Airways. The reviews are stored in the file \"British Airways Reviews.csv\" and the following information is provided:\n\n* **rating** - Score given by the customer (1=\"very poor\", 10=\"very good\")\n\n* **country** - The country where the customer resides\n\n* **review** - Written comment provided by the customer\n\nPerform the following tasks using the techniques introduced in Chapter 3 of the lecture notes:\n\na) Derive a sentiment score for each review based on the written comments. Explore how the score you obtain compares with the numerical rating given by the customer. \n\nb) Estimate a LDA model with $K=2$ topics. Explore the relation between the proportions $\\psi_{1,1},\\ldots,\\psi_{N,1}$ and the numerical score given by the customer. In your analysis you should carefully consider which words to include in the analysis. \n\nc) Based on your results in parts a) and b), discuss the performance of sentiment analysis and LDA in terms of identifying whether a review by a British Airways customer is more positive or more negative.   \n\n\n<p style=\"color:blue\"> *We start by loading the data and by creating an index for each review:*</p>\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nBA <- read.csv( \"data/British Airways Reviews.csv\" )\nBA <- BA %>% mutate( Index=1:nrow(BA) ) \n```\n:::\n\n\n<p style=\"color:blue\"> *To perform sentiment analysis, we will consider the AFINN sentiment lexicon:*</p>\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nAFINN <- read.csv(\"data/AFINN Sentiment Lexicon.csv\")\n```\n:::\n\n\n<p style=\"color:blue\"> *The first step is to split the reviews into individual words and assign each word its sentiment score:*</p>\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nBA_sentiment <- BA %>%\n  unnest_tokens( word, review ) %>%\n  inner_join( AFINN, by=\"word\" )\n```\n:::\n\n\n<p style=\"color:blue\"> *For each review we calculate its average sentiment and use box plots to visualise the distribution of the calculated sentiment score for the different ratings:*</p>\n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nBA_sentiment %>% \n  group_by( factor(Index) ) %>%\n  summarise( rating = rating[1], sentiment = mean( value ) ) %>%\n  ggplot( aes( x=factor(rating), y=sentiment ) ) +\n  geom_boxplot( ) + \n  labs( x=\"Rating\", y=\"Sentiment Score\" )\n```\n\n::: {.cell-output-display}\n![](Homework-6-Solutions_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n<p style=\"color:blue\"> *We find that the calculated sentiment score increases with the rating, with reviews which received no rating recording the lowest median sentiment score. As such, the median sentiment score increases with the positivity of the review / customer satisfaction.*</p>\n  \n  <p style=\"color:blue\"> *Let's move on the second part. The first task is to decide which words should be considered when estimating topics. While we should remove stop words when performing LDA, in this particular case we may want to keep the ones that represent emotional intent. One option is thus to define a new stop list which contains all the words from our standard stop list excluding the ones in the Bing sentiment lexicon (we use it because it includes more words than AFINN)*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBing <- read.csv(\"data/Bing Sentiment Lexicon.csv\") \nstop_words_sentiment <- stop_words %>% anti_join( Bing, by=\"word\") \n```\n:::\n\n\n<p style=\"color:blue\"> *We are now ready to perform the steps required to perform LDA, beginning with deriving the document-term matrix:*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBA_count <- BA %>%\n  unnest_tokens( word, review ) %>%\n  anti_join( stop_words_sentiment, by=\"word\" ) %>%\n  count( Index, word, sort = TRUE )\nBA_dtm <- BA_count %>% cast_dtm( Index, word, n )\n```\n:::\n\n\n<p style=\"color:blue\"> *We can now fit the LDA model with $K=2$ topics:*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBA_LDA <- LDA( BA_dtm, k = 2, method = \"Gibbs\", control = list(seed=1234) )\n```\n:::\n\n\n<p style=\"color:blue\"> *Interest lies in the proportions* $\\psi_{1,1},\\ldots,\\psi_{N,1}$  *which we can extract using*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBA_topics <- tidy( BA_LDA , matrix = \"gamma\" ) \n```\n:::\n\n\n<p style=\"color:blue\"> *Finally, we visualize the relation between the proportions and the ratings using a box plot:*</p>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nBA_topics %>% \n  filter( topic == 1 ) %>%\n  mutate( document = as.numeric(document) ) %>% \n  full_join( BA, by = c(\"document\"=\"Index\") ) %>%\n  ggplot( aes( x=factor(rating), y=gamma ) ) +\n  geom_boxplot() + labs( x=\"Rating\", y=\"Proportion of text from Topic 1\" )\n```\n\n::: {.cell-output-display}\n![](Homework-6-Solutions_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n<p style=\"color:blue\">*We find that reviews with a rating of 1 or 2 tend to feature less of Topic 1 than Topic 2, while the opposite applies for reviews receiving a rating of 3 or higher. The differences are small though and we see quite a variety in the proportions for all ratings, with proportions for each rating ranging between about 2-% and 80%.*</p>\n\n<p style=\"color:blue\">*When we compare the results for the sentiment analysis and LDA, we find that sentiment analysis performs best at identifying whether a review is positive or not. However, the performance is not stellar as even very positive reviews may be assigned a negative sentiment score. Consequently, the text data analysis tool box we introduced in this course can only capture the emotional intent of a customer review to a certain extent.*</p>\n\n<p style=\"color:blue\">*The weak performance of LDA is not very surprising, as there is no guarantee that the two estimated topics will be defined by whether the review uses a positive or negative wording. Reviews may use quite a few unique words, such as locations names. Let's have a look at the frequencies of the words in the Bing sentiment lexicon for the different topics:*</p>\n  \n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy( BA_LDA , matrix = \"beta\" ) %>%\n  inner_join( Bing, by=c(\"term\"=\"word\") ) %>%\n  mutate( topic = case_when( topic==1 ~ \"Topic1\", topic==2 ~ \"Topic2\") ) %>%\n  pivot_wider( names_from = topic, values_from = beta, values_fill = 0 ) %>%\n  ggplot( aes(x=Topic1, y=Topic2) ) + geom_point() +  \n  geom_text( aes(label=term), check_overlap = TRUE, vjust=1 ) + \n  coord_trans( x=\"sqrt\", y=\"sqrt\" ) + theme_bw() + \n  labs( x=\"Term Frequency in Topic 1\", y=\"Term Frequency in Topic 2\" )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in inner_join(., Bing, by = c(term = \"word\")): Detected an unexpected many-to-many relationship between `x` and `y`.\ni Row 24547 of `x` matches multiple rows in `y`.\ni Row 2698 of `y` matches multiple rows in `x`.\ni If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `coord_trans()` was deprecated in ggplot2 4.0.0.\ni Please use `coord_transform()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Homework-6-Solutions_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=50%}\n:::\n:::\n\n\n<p style=\"color:blue\">*We see that LDA did actually quite a good job: words we would assign with a positive sentiment are mainly in Topic 1, while words with a negative sentiment can mostly be found in Topic 2. As such, the fact that most of the estimated proportions being in the 40-60% range is down to the two topics having quite a lof of common words. *</p>",
    "supporting": [
      "Homework-6-Solutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}