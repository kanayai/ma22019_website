{
  "hash": "52c59af7ec1f708340489220ba8d339a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MA22019 2025 - Computer Lab 5\"\nsubtitle: \"Mise en place\"\ndescription: \"To work on the lab on date xx\"\ncategories: \"Lab\"\n---\n\n\n\n### **Overview**\n\n\nTutorial Question 1 is similar to Exercises 1-3, while Tutorial Question 2 explores how well the type of sentiment analysis we introduced performs at assessing sentiment for product reviews. Should time permit, you may want to work on the Homework Question during the tutorial. \n\n\nYou may want to load the following packages before starting the exercise:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary( dplyr )\nlibrary( ggplot2 )\nlibrary( tidytext )\nlibrary( wordcloud )\nlibrary( stringr )\n```\n:::\n\n\nWhen working on a University PC, you have to first install the tidytext and wordcloud packages. The installation of the textdata package is quite cumbersome, and thus I provide the AFINN and Bing sentiment lexicons as .csv files for your convenience. You can load them using\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAFINN <- read.csv( \"data/AFINN Sentiment Lexicon.csv\" )\nBing <- read.csv( \"data/Bing Sentiment Lexicon.csv\" )\n```\n:::\n\n\n\n\n\n### **Tutorial Question 1 - Word frequency analysis for** *Les Misérables*\n\nWe want to analyse the book *Les Misérables* by Victor Hugo in terms of the words used therein. The file \"LesMis.csv\" contains the data as provided by Project Gutenberg, but with the metadata at the beginning and end already removed. Consider the following questions:\n\na) Extract the individual words from the text, and remove any stop words and underscores.\n\nb) Find the 10 most common in *Les Misérables* (excluding stop words) and create a bar plot which visualizes their number of occurrences.\n\nc) Create a word cloud for the 30 most frequently used words (excluding stop words).\n\n\n### **Tutorial Question 2 - Amazon Reviews** \n\nOne important application area for sentiment analysis concerns the analysis of customer reviews. To explore how good the AFINN lexicon performs at capturing the overall sentiment of a review, we consider 1,000 Amazon product reviews. The data is stored in the file “AmazonReviews.csv”.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nReviews_raw <- read.csv( \"data/AmazonReviews.csv\" )\n```\n:::\n\n\nThe data provides the rating (\"1 Star\" to \"5 Stars\") and the accompanying text for each review. We want to derive the sentiment for each review and then compare it to the given score to assess how well we perform at capturing the sentiment of the text.\n\na) Using the AFINN sentiment lexicon, for each review, calculate the average sentiment per word.\n\nb) Plot the average sentiments calculated in part a) against the star ratings. What do you conclude?  \n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}