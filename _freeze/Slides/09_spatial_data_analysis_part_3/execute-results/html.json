{
  "hash": "98215ae3fc0f7fe8f2dc7764d7051389",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Spatial Data Analysis (Part 3)\"\nsubtitle: \"Lecture\"\ndate: \"2 April 2025\"\n---\n\n\n\n\n::: {.cell}\n\n:::\n\n\n## Plan for Today\n\nWe finish the remaining content in the lecture notes:\n\n* Comments on semi-variogram and PCA\n\n* Visualization of point pattern data (Sections 4.5)\n\n* Quadrat counting and kernel smoothed intensity function (Section 4.6)\n\n* Visualizing lattice/areal data (Section 4.7)\n\nThere will be a revision class in Week 10 (after the Easter break). Look out for a message about a poll on Moodle.\n\n# Some comments on last week's content\n\n## Semi-variogram - width and cutoff \n\n\nThe **width** in the variogram() function determines the number of points used to estimate $\\hat\\gamma(h)$:\n\n* A too small value means that estimates are highly uncertain\n\n* A too large value means that important aspects may be missed\n\n\n\nThe **cutoff** determines which range of distances we consider: \n\n* A too small value may imply that we miss important features\n\n* A too large value increases the risk of spurious relations affecting our conclusions\n\n\n\n## What to look out for? \n\n\nIt may be useful to consider the number of points per estimate:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngamma_hat$np\n```\n:::\n\n\nIf the number of points is too small, it may be worth changing the width or cutoff.\n\n\n\nCertain patterns in the semi-variogram may, for instance, be due to the constant mean assumption not being satisfied. \n\n**However**, such features may also be caused by randomness while all assumptions hold.\n\n\n\n## PCA - when does it work well?\n\nIdeally we want the data to lie in a low-dimensional linear subspace:\n\n* Only a few eigenvectors need to be considered for exploration\n\n* Good potential for dimension reduction\n\nWe have not really covered the topic in enough depth to introduce methods for exploring whether the data lies in a linear subspace in our examples.\n\nInstead, we only explore whether a linear relation between pairs of variables is realistic - we should pick spatially close sites.\n\n## Illustration\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09_spatial_data_analysis_part_3_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=95%}\n:::\n:::\n\n\nWe find quite a strong correlation and thus there is potential.\n\n# Analysis of point pattern data\n\n## Visualization \n\n\nWe can use the same techniques as for point-referenced data:\n\n* Placing points onto a shapefile\n\n* Creating maps with points on top\n\nLet's look at an example\n\n</br>**<span style='color: blue;'>-> Quarto Document WildFires.qmd</span>**\n\n\n\n**But**: We may not always see the structure clearly \n\n</br>**<span style='color: blue;'>-> Quarto Document Tornadoes.qmd</span>**\n\nThis leads us to the concept of **intensity** of a point process.\n\n## Intensity of a point process \n\n\nRemember that the locations and their number are **random** when working with point pattern data.\n\nLet $N(\\mathcal{B})$ be the random variable representing the number of points located in $\\mathcal{B}\\subseteq\\mathcal{S}$.\n\n\n\nThe **<span style='color: blue;'>intensity</span>** then describes $\\mathbb{E}\\left[N(\\mathcal{B})\\right]$ for any $\\mathcal{B}\\subseteq\\mathcal{S}$ with\n\n$$\n\\mu({\\mathcal{B}}) = \\mathbb{E}\\left[N(\\mathcal{B})\\right] = \\int_{\\mathcal{B}} \\lambda(\\mathbf{s}) \\mathrm{d} \\mathbf{s}.\n$$\n\nWe refer to $\\lambda:\\mathcal{S}\\to\\mathbb{R}_+=\\{x\\in\\mathbb{R}:x\\geq0\\}$ as the **intensity function**.\n\n\n## Analysis of the intensity function\n\n\nWe say that that the point process is \n\n* **homogeneous** when $\\lambda(\\cdot)$ is constant\n\n* **non-homogeneous** when $\\lambda(\\cdot)$ is not constant\n\n\n\n\nIn what follows, we descrive two techniques for visualizing the intensity function:\n\n* Quadrat counting\n\n* Kernel smoothed intensity function\n\n\n\n# Quadrat Counting\n\n## Overview {.smaller}\n\nGiven observed locations $\\mathbf{s}_1,\\ldots,\\mathbf{s}_n$, we perform three steps:\n\n1. Split $\\mathcal{S}$ into disjoint areas $\\mathcal{B}_1,\\ldots,\\mathcal{B}_m$ which are set as rectangles (**quadrats**).\n\n2. Count the number of points in $\\mathcal{B}_j$ as an estimate for $\\mathbb{E}\\left[N(\\mathcal{B}_j)\\right]$,\n\n$$\n\\widehat{\\mu(\\mathcal{B}_j)} = \\sum_{i=1}^n \\mathbb{I}\\{\\mathbf{s}_i \\in \\mathcal{B}_j\\}.\n$$\n\n3. The intensity function is then estimated as\n\n$$\n\\hat{\\lambda}^{(Q)}(\\mathbf{s}) = \\frac{\\widehat{\\mu(\\mathcal{B}_j)}}{|\\mathcal{B}_j|},\\quad\\mathbf{s}\\in\\mathcal{B}_j,\n$$\n\nwhere $|\\mathcal{B}_j|$ denotes the area of $\\mathcal{B}_j$.\n\n## Details\n\nThe **quadratcount()** function in the spatstat R package performs steps 1) and 2).\n\nWe have to balance two aspects:\n\n- $\\mathcal{B}_j$ should be small enough such that $\\lambda(\\mathbf{s})$ is approximately constant for all $\\mathbf{s}\\in\\mathcal{B}_j$.\n\n- $\\widehat{\\mu(\\mathcal{B}_j)}$ should be a reliable estimate for $\\mu(\\mathcal{B}_j)$. \n\n**<span style='color: blue;'>-> Quarto Document WildFires.qmd</span>**\n\n\n# Kernel Smoothed Intensity Function\n\n## Overview \n\n\nSuppose we have a probability density (kernel) $K(\\cdot)$ and, similar to a density plot, we define\n\n\n$$\n\\hat\\lambda^{(K)}(\\mathbf{s}) = \\sum_{i=1}^{n} K\\left(||\\mathbf{s}-\\mathbf{s}_i||_2\\right),\n$$\n\nwhere $||\\mathbf{s}-\\mathbf{s}_i||_2$ is the Euclidian distance.\n\n\n\nHowever, this approach assigns positive probability to areas outside $\\mathcal{S}$ and thus\n\n\n$$\n\\int_{\\mathcal{S}} \\hat{\\lambda}^{(K)}(\\mathbf{s}) \\mathrm{d}\\mathbf{s} \\neq n.\n$$\n\n\n## Edge correction\n\nThe **uniformly corrected smoothed kernel intensity function** is defined as\n\n\n$$\n\\hat\\lambda^{(C)}(\\mathbf{s}) = \\frac{1}{g(\\mathbf{s})}\\sum_{i=1}^{n} K\\left(||\\mathbf{s}-\\mathbf{s}_i||_2\\right),\n$$\n\nwhere \n\n$$\ng(\\mathbf{s}) = \\int_{\\mathcal{S}} K(\\mathbf{s}-\\tilde{\\mathbf{s}}) \\mathrm{d}\\tilde{\\mathbf{s}}.\n$$\n\n\nThis correction is available in the spatstat R package.\n\n</br>**<span style='color: blue;'>-> Quarto Document WildFires.qmd</span>**\n\n## Analysis of Tornadoes\n\nLet's consider a second example\n\n</br>**<span style='color: blue;'>-> Quarto Document Tornadoes.qmd</span>**\n\n\n# Visualizing Lattice Data\n\n## Overview\n\nWe will consider two examples:\n\n* Population density across London boroughs\n\n* Number of tornadoes per US state\n\nIn both of these cases, we will exploit an aspect of shapefiles we have not considered so far.\n\nSpecifically, we make use of the shapefile coming with a data frame, which permits data wrangling.\n\n\n## Example 1 - Boroughs in London \n\nLet's load a shapefile for London\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLondon <- read_sf(\"data/shapefiles/London.shp\")\nclass(London)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n\n\n:::\n:::\n\n\nWe see that **London** includes a data frame. \n\n**All entries except for the \"geometry\" can be manipulated.**\n\nLet's visualize population density for the different boroughs.</br>**<span style='color: blue;'>-> Quarto Document</span>**\n\n\n## Example 2 - Tornadoes in the US\n\nThe data in \"Tornadoes.csv\" provides observations on tornadoes for 1950-1921 for the whole US.\n\nLet's visualize the number of tornadoes recorded for each state.\n</br>**<span style='color: blue;'>-> Quarto Document Tornadoes.qmd</span>**\n\n## Summary\n\n* We covered all the relevant material:\n\n  + Visualization of point pattern and lattice data\n\n  + Exploration of the intensity of a point process\n\n* Problem Sheet 8 provides some practice and will be considered in the tutorial in Week 10.\n\n* Revision lecture in Week 10:\n\n  + We will revisit two topics of your choice\n\n  + Selection via a feedback form on Moodle (the two most popular choices win)\n\n\n\n",
    "supporting": [
      "09_spatial_data_analysis_part_3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}