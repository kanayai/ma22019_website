{
  "hash": "8e5b5118e257a4bc16a374a6e5c10d84",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Problem Class 4 - Solution\"\nauthor: \"Dr. Karim Anaya-Izquierdo\"\nformat: html\n---\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidytext)\nlibrary(stringr)\n```\n:::\n\n\n\n## Background\n\nJane Austen wrote seven novels, and we consider six of these: \"Sense and Sensibility\", \"Pride and Prejudice\", \"Mansfield Park\", \"Emma\", \"Northanger Abbey\" and \"Persuasion\". \n\nAll novels are available via Project Gutenberg and we will analyze similarities and differences of the different books in the following. We start by loading the text data which is available in the file \"Data/JaneAusten.csv\" on Moodle:\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten_raw <- read.csv(\"data/janeausten.csv\" )\n```\n:::\n\n\nWe will analyze the six books and\n\n1) Identify the most common words (except stop words) for each book\n\n2) Compare the six books in terms of their sentiment\n\n\n## Word frequency analysis\n\nAs before, we first have to bring the data into a usable format and remove stop words.\n\n**Task 1:** Split the lines of text into individual words and remove all stop words and underscores.\n\n<p style=\"color:blue\">*We copy the code we used for the analysis of the book \"Jane Eyre\":*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten <- JaneAusten_raw %>%\n  unnest_tokens( word, text ) %>%\n  mutate( word = gsub( \"\\\\_\", \"\", word ) ) %>%\n  anti_join( stop_words, by=\"word\" )\n```\n:::\n\n\nWith the data in the desired format, we are ready to identify the most common words:\n\n**Task 2:** Extract the ten most common words (excluding stop words) for each book.\n\n<p style=\"color:blue\">*Since we want to consider each book separately, we need to first use the group_by() function before using the functions we used for extracting counts:*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten_Count <- JaneAusten %>%\n  group_by( title ) %>%\n  count( word, name = \"Count\" ) %>%\n  slice_max( Count, n=10 )\n```\n:::\n\n\nAfter identifying the most frequent words, let's visualize them. The following piece of code produces for each book a bar plot which visualizes the number of occurrences of the words identified in Task 2, i.e., the bar plot for a book provides information on the ten most common words (excluding stop words) contained in that book.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot( JaneAusten_Count, \n        aes( x=Count, y=reorder_within(word,Count,title), fill=title ) ) + \n  facet_wrap( ~title, scales = \"free\" ) + \n  geom_col( show.legend = FALSE ) + \n  scale_y_reordered() + theme_bw() + \n  labs( x=\"Count\", y=\"Word\" )\n```\n\n::: {.cell-output-display}\n![Bar plots illustrating the frequency of the ten most common words for each book.](analysis_of_jane_austen_-complete-_files/figure-html/JABP-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n**Task 3:** What is the benefit of using the functions **reorder_within()** and **scale_y_reordered()**? What do we conclude from the plot?\n\n<p style=\"color:blue\">*We have seen that we can use reorder() to order words according to their frequency. The functions reorder_within() and scale_y_reordered() allow us to do the same, but for subgroups. This is useful because we want to have a separate plot for each book.*</p>\n\n<p style=\"color:blue\">*The bar plots show that the names of the characters are used the most often, but a close inspection shows that \"time\" and \"miss\" are included in all bar plots.*</p>\n\nTo conclude our analysis on the words used within the books, we want to calculate the tf-idf values for each term.\n\n**Task 4:** Calculate the tf-idf value for each word and book. What do we conclude?\n\n<p style=\"color:blue\">*We apply the code as used in the analysis for the books by Charles Dickens:*</p>\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten_tf.idf <- JaneAusten %>% \n  count( word, title, sort=T ) %>%\n  bind_tf_idf( word, title, n ) %>%\n  arrange( desc(tf_idf) )\nslice_head( JaneAusten_tf.idf, n=10 )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        word                 title   n          tf      idf     tf_idf\n1     elinor Sense and Sensibility 685 0.018815063 1.791759 0.03371207\n2   marianne Sense and Sensibility 566 0.015546461 1.791759 0.02785552\n3     elliot            Persuasion 289 0.011328003 1.791759 0.02029706\n4      darcy   Pride and Prejudice 432 0.011019565 1.791759 0.01974441\n5     weston                  Emma 440 0.009446114 1.791759 0.01692516\n6     bennet   Pride and Prejudice 339 0.008647297 1.791759 0.01549388\n7  wentworth            Persuasion 218 0.008544998 1.791759 0.01531058\n8  knightley                  Emma 389 0.008351224 1.791759 0.01496338\n9      elton                  Emma 387 0.008308287 1.791759 0.01488645\n10   bingley   Pride and Prejudice 310 0.007907558 1.791759 0.01416844\n```\n\n\n:::\n:::\n\n\n<p style=\"color:blue\">*We can also visualize the words with highest tf-idf value by adapting the code used to produce bar plots for word frequency:*</p>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nJaneAusten_tf.idf%>%\n  group_by( title ) %>%\n  slice_max( order_by = tf_idf, n=10 ) %>%\n  ggplot( aes( x=tf_idf, y=reorder_within(word,tf_idf,title), fill=title ) ) + \n  facet_wrap( ~title, scales=\"free_y\") + \n  geom_col( show.legend = FALSE ) + \n  scale_y_reordered() + theme_bw() +\n  labs( x=\"tf-idf\", y=\"\" )\n```\n\n::: {.cell-output-display}\n![Bar plots illustrating the ten words with the highest tf-idf values for each book.](analysis_of_jane_austen_-complete-_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n<p style=\"color:blue\">*The displayed words are, as measured by the tf-idf, the most important to each novel and most readers would likely agree. We can also conclude that Jane Austen used similar language across her six novels, because more common words, such as \"time\" or \"sister\", are no longer in the plot. Consequently, what distinguishes one novel from the rest within the collection of her works are the names of people and places. This is the point of tf-idf, it identifies words that are important to one document within a collection of documents.*</p>\n\n\n\n## Sentiment analysis\n\nLet's study the sentiment of the books using the AFINN sentiment lexicon:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAFINN <- get_sentiments( \"afinn\" )\n```\n:::\n\n\nWe want to derive the sentiment score for each chapter in each book. To do this, we first need to identify which chapter each line belongs to. We can do this by adapting the code from Section 3.2 in the lecture notes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten_chapters <- JaneAusten_raw %>%\n  group_by( title ) %>%\n  mutate( chapter = cumsum( str_detect(\n    text, regex(\"^chapter \", ignore_case = TRUE)\n  ) ) ) %>%\n  filter( chapter > 0 ) %>%\n  ungroup()\n```\n:::\n\n\nThe next step is to split the lines of text into individual words and to match the words in the AFINN sentiment lexicon with the words in the books. As for Jane Eyre, we remove the word \"miss\" from the analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten_AFINN <- JaneAusten_chapters %>%\n  filter( chapter > 0 ) %>%\n  unnest_tokens( word, text ) %>%\n  mutate( word = gsub( \"_\", \"\", word ) ) %>%\n  inner_join( AFINN, by = \"word\" ) %>% \n  filter( word != \"miss\" )\n```\n:::\n\n  \n**Task 5:** Derive the aggregated sentiment score for each chapter using the AFINN sentiment lexicon.\n\n<p style=\"color:blue\">*We calculate the aggregate sentiment score as follows:*</p>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nJaneAusten_AFINN   <- JaneAusten_AFINN %>%\n  group_by( title, chapter ) %>%\n  summarise( sentiment = sum( value ) )\n```\n:::\n\n\nHaving derived the sentiment score for each book and chapter, we visualize the results:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot( JaneAusten_AFINN, aes( x=chapter, y=sentiment ) ) +\n  facet_wrap( ~title, scales=\"free_x\" ) +\n  geom_col( aes( fill=title ), show.legend = FALSE ) + \n  theme_bw() + labs( x=\"Chapter\", y=\"AFINN sentiment score\" ) \n```\n\n::: {.cell-output-display}\n![](analysis_of_jane_austen_-complete-_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=95%}\n:::\n:::\n\n\n**Task 6:** What do we conclude?\n\n<p style=\"color:blue\">*We see that almost all chapters have a positive sentiment score, i.e., this indicates that Jane Austen used a lot of words that are associated with a \"positive\" sentiment. However, we should keep in mind that not all parts of these books are actually happy stories, illustrating the limitations of our approach to measure sentiment. However, we can still comment on the differences in sentiment of chapters.*</p>\n",
    "supporting": [
      "analysis_of_jane_austen_-complete-_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}