---
title: "MA22019 2025 - Quiz 6"
subtitle: "Mise en place"
description: "To work after ..."
categories: "Quiz"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **Overview**

This week's problem sheet focuses on the text data analysis techniques covered in Sections 3.3.2 and 3.4 of the lecture notes. Exercises 1-2 help you with revising the content of the lecture in Week 6. You can check your solutions to these questions yourself by answering the Moodle quiz.


You may want to load the following packages before starting the exercise:

```{r, message=FALSE, warning=FALSE}
library( dplyr )
library( ggplot2 )
library( tidytext )
library( stringr )
library( tidyr )
library( topicmodels )
```

When working on a University PC, you have to first install the tidytext package and any dependencies using

```{r, eval=FALSE}
install.packages( "tidytext", dependencies = TRUE )
```

For the sentiment analysis you can load the sentiment lexicons using

```{r}
AFINN <- read.csv( "data/AFINN Sentiment Lexicon.csv" )
Bing <- read.csv( "data/Bing Sentiment Lexicon.csv" )
```


### **Exercise 1 - Comparing Moby Dick and Robinson Crusoe**

We want to consider the books *Moby Dick* and *The Life and Adventures of Robinson Crusoe*. The text for both books is provided in the file "AdventureBooks.csv" and we load it using 

```{r}
Books <- read.csv( "data/AdventureBooks.csv" )
```

Consider the following two questions:

a) Which five words (excluding stop words) are the most common in *Moby Dick*?

b) When considering a corpus which only includes *Moby Dick* and *The Life and Adventures of Robinson Crusoe*, which five words have the highest term frequency - inverse document frequency (tf-idf)?

### **Exercise 2 - Analysis of news articles**

In Section 4.4 we applied topic modelling to articles published in the New York Times. We now study another example. The file “Articles.csv” on Moodle provides the text for 2692 news articles from 2015. The articles were published either in the "business" or the "sports" category. In this exercise you will first repeat the steps from Section 4.4, and then explore how well your fitted model performs at identifying whether an article belongs to the "business" or "sports" category.

a) Treading each article as a separate document, derive the document term matrix for the set of articles and store it as **Articles_dtm**. 

With the document term matrix having been derived, we estimate the parameters of an LDA model with $K=2$ topics using:

```{r, eval=FALSE}
Articles_LDA <- LDA( Articles_dtm, k = 2, method="Gibbs", control = list(seed=2024) )
```

b) For each article, extract the proportions with which the different topics feature. Is there a difference in proportions between "business" and "sports" articles?

c) Which are the five most common words in each of the two topics?


