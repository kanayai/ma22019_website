---
title: "MA22019 - Spatial Data Analysis (Part 2)"
author: "Christian Rohrbeck"
date: "26 March 2025"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, warning=FALSE, message=FALSE}
colorize <- function(x, color="blue") {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
library(dplyr)
library(ggplot2)
library(sf)
```

## Plan for Today

We introduce two more techniques for analysing point-referenced data:

* Semi-variogram (Section 4.3)

* Principal component analysis (Section 4.4)

The two other types of spatial data will be considered in more detail in Week 9.

# Spatial Dependence

## Motivation

In terms of analyzing point-referenced data, we explored 

- Visualization

- Inverse distance weighting

The latter makes certain assumptions to predict values at unobserved locations.

**`r colorize("Which assumption may we make?")`**


## Sea Surface Temperature Anomalies

Let's consider a data set similar to Problem Class 5:

```{r, fig.align='center', out.width='65%', echo=FALSE}
SSTA <- read.csv("Sea Surface Temperature Anomalies.csv")
SSTA_sf <- st_as_sf( SSTA, coords=c("lon","lat") ) %>% 
  st_set_crs(4326)
ggplot( data=SSTA_sf ) + theme_bw() + 
  geom_sf( aes(color=Anomaly) ) + labs( color="Â°C" ) +
  theme( axis.text = element_text(size=14),
         legend.text = element_text(size=12) )
```

**What do we observe?**

## Spatial dependence

Locations which are spatially close appear to have similar values.

This suggests that observations are **dependent**!

Today we introduce two techniques for exploring this **`r colorize("spatial dependence")`.**

# The (semi-)variogram

## Mathematical definition 


Let $X(\mathbf{s})$ denote random variable at $\mathbf{s}\in\mathcal{S}$. 

We assume that $E[X(\mathbf{s})]$ is constant.</br> **`r colorize("Is this reasonable for our data?")`**



We measure dependence between $X(\mathbf{s})$ and $X(\tilde{\mathbf{s}})$ via the **semi-variogram**
\[
\gamma(\mathbf{s},\tilde{\mathbf{s}}) = \frac{1}{2} \mathrm{E}\left[\{X(\mathbf{s})-X(\tilde{\mathbf{s}})\}^2\right].
\]



## Properties

The semi-variogram satisfies 

- $\gamma(\mathbf{s},\tilde{\mathbf{s}})\geq 0$ and $\gamma(\mathbf{s},\mathbf{s})=0$.

- For $X(\mathbf{s})$ and $X(\tilde{\mathbf{s}})$ i.i.d., $\gamma(\mathbf{s},\tilde{\mathbf{s}})=\mathrm{Var}[X(\mathbf{s})].$


## Estimation I 


**Why can we not easily estimate $\gamma(\mathbf{s},\tilde{\mathbf{s}})$?**



To estimate $\gamma(\mathbf{s},\tilde{\mathbf{s}})$, we assume that the spatial random process is $X(\mathbf{s})$ **stationary** and **isotropic**.
  


As such there exists $\tilde{\gamma}:\mathbb{R}_+\to\mathbb{R}_+$ with
\[
\gamma(\mathbf{s} , \tilde{\mathbf{s}}) = \tilde{\gamma}(||\mathbf{s}-\tilde{\mathbf{s}}||),
\]
where $||\mathbf{s}-\tilde{\mathbf{s}}||$ denotes the distance between the sites.


## Estimation II

If our assumptions hold, we can estimate $\tilde{\gamma}(h)$, $h>0$, as follows:

1. Find all pairs of sites with a distance similar to $h$. This gives the set $\mathcal{N}_h =\{(i,j):||\mathbf{s}_i - \mathbf{s}_j||\approx h\}$.    

2. Calculate the estimate for $\tilde\gamma(h)$ as
\[
\hat\gamma(h) = \frac{1}{2|\mathcal{N}_h|} \sum_{i,j \in\mathcal{N}_h} (x_i-x_j)^2.
\]

We use the function **variogram()** in the **gstat** R package for this. 

**Remark**: We have to convert the data into a specific format.

## What are we looking for?

In many applications we find the following features:

1. **$\hat\gamma(h)$ increases with increasing distance.**</br> This suggests that spatial dependence becomes weaker the further sites are apart.

2. **$\hat\gamma(h)$ levels off at a certain distance.** </br> This marks the point when sites are so far apart that the realizations are close to independent.

## Example

Let's look at the example on sea surface temperature anomalies

**`r colorize("-> R Markdown file")`**

## Summary

To analyse spatial dependence using the semi-variogram, we need to 

1. Consider whether it is reasonable to assume that dependence is fully described by spatial distance and that all sites have the same mean

2. Estimate the semi-variogram using the **sp** and **gstat** package

3. Interpret the estimated semi-variogram

You will learn more about the mathematical details in Year 3 Statistics.

# Principal Component Analysis (PCA)

## Motivation 


Let's assume we have multiple observations per spatial location.

We use $x_{i,t}$ to denote the $t$-th observation for site $i$.

**`r colorize("How could we visualize such data?")`**



In many applications we want to 

* Understand the spatial structure of the data

* Perform dimension reduction


## Motivation - Data for two sites

```{r, out.width='60%', fig.height=4, fig.width=4, fig.align='center', echo=FALSE}
set.seed(2025)
x1 <- rnorm( 200, mean=2, sd=4 )
x2 <- rnorm( 200, mean=x1, sd=1 )
X  <- data.frame( "Site1"=x1, "Site2"=x2 )
ggplot( X, aes(x=Site1, y=Site2) ) + geom_point() + 
  labs( x="Data for Site 1", y="Data for Site 2" ) + theme_bw()
```

## Can we reduce it to a single variable?

```{r, echo=FALSE, fig.align='center', out.width='60%', fig.height=4, fig.width=4}
Sigma <- cov( X )
Eigen <- eigen( Sigma )
X_proj <- Eigen$vectors[,1] %*% t( as.matrix(X) %*% Eigen$vectors[,1] )
X_proj <- data.frame( x1=X_proj[1,], x2=X_proj[2,] )
ggplot( X, aes(x=Site1, y=Site2) ) + geom_point() + 
  labs( x="Data for Site 1", y="Data for Site 2" ) + theme_bw() +
  geom_point( data=X_proj, aes(x=x1, y=x2), color="red" )
```

## How does PCA work?

1. Calculate $\tilde{x}_{i,t} = (x_{i,t} - \bar{x}_i)/\hat\sigma_i$.

2. Derive the matrix
\[
\Sigma = \frac{1}{T-1}\sum_{t=1}^T \tilde{\mathbf{x}}_t \tilde{\mathbf{x}}_t^{\mathrm{T}}.
\]
This matrix is also known as the **empirical covariance matrix**.

3. Derive and study the eigenvalues and eigenvectors of $\Sigma$, $\Sigma = \mathbf{UDU}^{\mathrm{T}}$. 

## Analysis of the eigenvectors 


Each eigenvector provides insight on the spatial structure in the data.

-> We create plots of the eigenvectors and interpret them sequentially

**`r colorize("Do we need to consider all eigenvectors?")`**


No (usually), the eigenvalues will help us with this.
 
## Analysis of the eigenvalues


We have eigenvalues $\lambda_1 > \lambda_2 > \cdots > \lambda_n$

Consider the ratio
\[
\frac{\sum_{j=1}^m \lambda_j}{\sum_{j=1}^n \lambda_j}.
\]

The smallest $m$ for which the ratio exceeds 0.9 gives the number of eigenvectors we should plot.


This is one of several rules-of-thumb, but you only need to know this one.

## Example

Let's analyse rainfall data for sites across the US state Colorado.

We have

* $n=30$ cities

* Monthly amount of precipitation across 2010-2023. So we have $T=168$ observations per site. 

**`r colorize("-> R Markdown file")`**




## Summary

While PCA may seem like a black box, it is very powerful method and has many applications beyond spatial data analysis.

The key steps are

1. Apply the prcomp() function to the matrix of observations

2. Study the eigenvalues to determine how many eienvectors need to be considered

3. Visualize the eigenvectors and make conclusions about the spatial structure in the data

When does PCA work? -> **Linearity of variables**


## Looking ahead

* We will conclude the content next week (Week 9).

* There will be a problem sheet which will be considered in the tutorial after Easter (Tuesday in Week 10).

* The lecture in Week 10 will be a revision lecture.</br> Look out for an announcement on Moodle!

* Coursework 2 will be released on the Friday in Week 10







