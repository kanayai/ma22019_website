---
title: "Analysis of the work by Charles Dickens"
date: "12/03/2025"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading packages and data

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(tidytext)
library(stringr)
library(tidyr)
library(topicmodels)
```

```{r}
Dickens_raw <- read.csv( "Dickens.csv" )
```

```{r}
head(Dickens_raw)
```

# Term frequency - inverse document frequency

## Prepare the data {-}

```{r}
Dickens <- Dickens_raw %>%
  unnest_tokens( word, text ) %>% 
  mutate( word = gsub( "_", "", word ) )
```

## Calculate tf-idf with stop words kept in the analysis {-}

Extract counts for each word

```{r}
DickensCount <- Dickens %>% count( title, word, sort=TRUE )
```

```{r}
slice_head(DickensCount, n=10)
```

Calculate tf-idf using bind_tf_idf() from the tidytext package:
  
```{r}
Dickens_tf.idf <- DickensCount %>% 
  bind_tf_idf( word, title, n ) %>%
  arrange( desc(tf_idf) ) %>%
  mutate( idf=round(idf,2) )
slice_head( Dickens_tf.idf, n=10 )
```


## Calculate tf-idf with stop words removed {-}

Extract counts for each word

```{r}
DickensCount <- Dickens %>% 
  anti_join( stop_words, by="word" ) %>%
  count( title, word, sort=TRUE )
```

Calculate tf-idf using bind_tf_idf() from the tidytext package:
  
```{r}
Dickens_tf.idf <- DickensCount %>% 
  bind_tf_idf( word, title, n ) %>%
  arrange( desc(tf_idf) ) %>%
  mutate( idf=round(idf,2) )
slice_head( Dickens_tf.idf, n=10 )
```


# Topic modelling


## Create identifier for each chapter {-}


### Extract books and chapter {-}

```{r}
Dickens_chapters <- Dickens_raw %>%
  filter( title %in% c( "Great Expectations","A Tale of Two Cities" ) ) %>%
  group_by( title ) %>%
  mutate( chapter = cumsum( 
    str_detect( text, regex( "^chapter ", ignore_case = TRUE ) ) 
  ) )
```

### Create identifier {-}

```{r}
Dickens_chapters <- Dickens_chapters %>%
  filter( chapter > 0 ) %>%
  unite( col=document, title, chapter )
```

```{r}
head(Dickens_chapters)
```


## Construct the document term matrix {-}

Split text into individual words and remove stop words:

```{r}
Dickens_chapters <- Dickens_chapters %>%
  unnest_tokens( word, text ) %>%
  mutate( word = gsub( "_", "", word ) ) %>%
  anti_join( stop_words, by="word" )
```

Extract counts for each word per chapter

```{r}
Dickens_chapters <- Dickens_chapters %>% count( document, word, sort = TRUE )
```

Construct the document term matrix

```{r}
Dickens_dtm <- Dickens_chapters %>% cast_dtm( document, word, n )
```

```{r}
Dickens_dtm
```


## Estimate Laten Dirichlet Allocation model {-} 

```{r, warning=FALSE, message=FALSE}
Dickens_LDA <- LDA( Dickens_dtm, k=2, method = "Gibbs", control=list(seed=123) )
```

## Analysis of the estimates {-}

### Make up of the chapters {-}

```{r}
Dickens_topics <- tidy( Dickens_LDA , matrix = "gamma" ) 
Dickens_topics %>% slice_head( n=4 )
```

```{r, fig.align='center', out.width='50%'}
Dickens_topics %>%
  separate( document, c("title", "chapter"), sep="_", convert=TRUE ) %>%
  ggplot( aes( x=factor(topic), y=gamma ) ) + 
  facet_wrap( ~title ) + geom_boxplot() + 
  labs( x="Topic", y="Proportion" )
```

### Make up of the topics {-}

```{r}
tidy( Dickens_LDA , matrix = "beta" ) %>%
  group_by( topic ) %>%
  slice_max( beta, n=3 )
```

```{r, fig.align='center', out.width='60%', fig.height=5, fig.width=6}
tidy( Dickens_LDA , matrix = "beta" ) %>%
  mutate( topic = case_when( topic==1 ~ "Topic1", topic==2 ~ "Topic2") ) %>%
  pivot_wider( names_from = topic, values_from = beta, values_fill = 0 ) %>%
  ggplot( aes(x=Topic1, y=Topic2) ) + geom_point() +  
  geom_text( aes(label=term), check_overlap = TRUE, vjust=1 ) + 
  coord_trans( x="sqrt", y="sqrt" ) + theme_bw() +
  labs( x="Term Frequency in Topic 1", y="Term Frequency in Topic 2" )
```