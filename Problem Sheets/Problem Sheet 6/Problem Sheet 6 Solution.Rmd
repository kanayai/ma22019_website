---
title: "MA22019 2025 - Solutions for Problem Sheet 6"
author: "Visualization of point-referenced data and inverse distance weighting"
output:
  html_document: default
  pdf_document: default
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **Overview**

This week's exercises help you with revising Sections 4.1 and 4.2 in the lecture notes. Exercises 1 asks you to identify the correct type of spatial data. Exercises 2 and 3 provide additional opportunities to visualize spatial data using shapefiles and maps, and to interpret the plots.

Tutorial Question 1 considers an example similar to that in the lecture notes, and Tutorial Question 2 focuses on the use of projections for visualizing data.

The Homework question is inspired by one of last year's coursework questions. Besides the creation of plots, the question asks you to carefully discuss the assumptions we make when applying the tools covered in Sections 4.1 and 4.2.

Your answer to the Homework Question can be submitted on Moodle to your tutor for feedback. The submission deadline is 17:00 on Thursday 27 March 2025. You should submit a single Word, PDF or HTML file that provides your R code, any created R output and all your comments.

You may want to load the following packages before starting the exercises:

```{r, message=FALSE, warning=FALSE}
library( dplyr )
library( ggplot2 )
library( sf )
library( ggspatial )
library( prettymapr )
```

### **Exercise 1 - Types of spatial data**

For each of the following applications, decide whether the data will be point-referenced, point pattern or lattice/areal data: 

a) Occurrence of tornadoes across Europe

<p style="color:blue"> *The locations at which tornadoes occur are unknown/random and thus we will likely have point pattern data.*</p>

b) Air pollution levels across a city

<p style="color:blue"> *We may have information from measurement stations across the city. The locations of the measurement stations will be known and our variable of interest is the concentration of pollutants. Consequently, we have point-referenced data.*</p>

c) Strength of mobile phone signal

<p style="color:blue"> *Such data could be collected by measuring signal strength at a number of fixed locations. This would then give point-referenced data.*</p>

d) Damage caused by the great spruce bark beetle across Western England

<p style="color:blue"> *It is not feasible to investigate each individual tree. Instead, we will be given information on whether a woodland area is affected by the bark beetle or not. This would result in lattice / areal data.*</p>

e) Sightings of Type Ia supernova

<p style="color:blue"> *The locations of Type Ia supernova are unknown and we thus will have point pattern data. This is one application of spatial data analysis which does not consider observations located on earth. This results in a coordinate system different to the latitude/longitude system considered in most examples.*</p>


### **Exerise 2 - Rainfall across New Zealand**

The file "NewZealandRain.csv" provides the aggregated rainfall between 01/09/2019 and 30/11/2019 for various locations across New Zealand. A shapefile for New Zealand is provided in the file "ShapeFileNZ.Rdata".

a) Load the shapefile and create a plot of New Zealand. 

<p style="color:blue"> *We load and plot the data as we did for the shapefile of Germany in Section 4.1.2 of the lecture notes:*</p>

```{r, out.width='80%', fig.height=4, fig.width=7, fig.align='center'}
NewZealand <- read_sf( "Shapefiles/NZ.shp" )
ggplot( NewZealand ) + geom_sf() + theme_bw() + 
  labs( x="Longitude", y="Latitude" )
```

b) Load the data in "NewZealandRain.csv". Add points to the plot in part a) which represent the locations contained in "NewZealandRain.csv", and use the visual cue colour to visualize the amount of precipitation on logarithmic scale recorded at the various locations

<p style="color:blue"> *We first load the weather observations:*</p>

```{r}
Rain <- read.csv( "NewZealandRain.csv" )
```

<p style="color:blue"> *We again slightly adapt the code from Setion 4.1.2 in the lecture notes to combine the shapefile and the points in a single plot:*</p>

```{r, out.width='80%', fig.align='center'}
ggplot( NewZealand ) + geom_sf( color="white" ) + theme_dark() + 
  geom_point( data=Rain, aes(x=lon, y=lat, color=log(precipitation) ) ) + 
  scale_color_distiller( palette="Blues", trans="reverse" ) +
  labs( x="Longitude", y="Latitude", color="Log(Precipitation)" ) 
```

c) Use inverse distance weighting with power parameter $p=2$ to estimate the amount of precipitation between 01/09/2019 and 30/11/2019 for the following two locations: (i) 177°E Longitude and 38°S Latitude; (ii) 166°E Longitude and 51°S Latitude. You should use the original data and not apply the logarithmic scale from part b). Submit your answers (to two decimal places) in the Moodle quiz.

<p style="color:blue"> *The first step is to define the IDW() function we used in Section 4.2.2:*</p>

```{r}
IDW <- function( X, S, s_star, p){
  d <- sqrt( (S[,1]-s_star[1])^2 + (S[,2]-s_star[2])^2 )
  w <- d^(-p)
  if( min(d) > 0 )
    return( sum( X * w ) / sum( w ) )
  else 
    return( X[d==0] )
}
```

<p style="color:blue"> *We then adapt the code in Section 4.2.2 to use inverse distance weighting to get estimates for the amount of precipitation at the two locations:*</p>

```{r}
coord <- cbind( Rain$lon, Rain$lat )
IDW( X=Rain$precipitation, S=coord, s_star=c(177,-38), p=2.0 )
IDW( X=Rain$precipitation, S=coord, s_star=c(166,-51), p=2.0 )
```

<p style="color:blue"> *We predict that the amount of precipitation for Location (i) was 225 mm, while it was 400mm for Location (ii).*</p>



### **Exercise 3 - Earthquakes across Japan**

The files "Japan earthquakes.csv" contains data for earthquakes which affected Japan between 2011 and 2018. The data has been collected by the United States Geological Survey. We want to use spatial data analysis to investigate the locations of the strongest earthquakes. 

a) Load the data and extract the earthquakes with a magnitude of 6 or higher. 

<p style="color:blue">*We start by loading the data*</p>

```{r}
Earthquakes <- read.csv( "Japan earthquakes.csv" )
```

<p style="color:blue">*We can now apply the filter() function from dplyr to extract the earthquakes we are interested in:*</p>

```{r}
Earthquakes_strong <- filter( Earthquakes, mag>=6.0 )
```


b) Create a map to visualize the locations and magnitude of the earthquakes extracted in part a).

<p style="color:blue">*If we use the ggspatial package, we can directly create the map:*</p>

```{r, out.width='70%', fig.align='center', message=FALSE, warning=FALSE}
ggplot( Earthquakes_strong, aes(x=longitude, y=latitude) ) + 
  annotation_map_tile( zoom=5 ) + 
  geom_spatial_point( aes( color = mag ) ) + 
  scale_color_distiller( palette="Reds", trans="reverse" ) +
  labs( x="Longitude", y="Latitude", color="Magnitude" ) + 
  theme_bw()
```


c) Go to Moodle and complete the quiz.


### **Tutorial Question 1 - Temperature across north-eastern Brazil**

The file "Brazil.csv" contains average daily temperatures between 2000 and 2021 for 149 weather stations in north-eastern Brazil. You also given a shapefile for Brazil. We want to analyze the data using the techniques for point-referenced data introduced in the lecture.  

a) Visualize the locations of the weather stations and average daily temperature using the provided shapefile. Use the functions xlim() and ylim() to zoom in on the area of Brazil the stations are located in.

<p style="color:blue"> *We start by loading the shapefile and the data for the weather stations:* </p>

```{r}
Brazil <- read_sf( "Shapefiles/Brazil.shp" )
Temperature <- read.csv( "Brazil Temperature.csv" )
```

<p style="color:blue"> *Using the code from Section 4.1.2 and the functions xlim() and ylim() we produce the plot as required:* </p>

```{r, out.width='70%', fig.align='center', fig.height=4}
ggplot( Brazil ) + geom_sf() + theme_bw() + 
  geom_point( data=Temperature, aes(x=Lon, y=Lat, color=MeanTemp) ) +
  scale_color_distiller( palette="Reds", trans="reverse" ) +
  xlim( -48, -34 ) + ylim( -20, 0 ) + labs( x="Longitude", y="Latitude" )
```

b) Create a map with the ggspatial R package that illustrates the spatial locations of the weather stations and the recorded average daily temperatures. What do you conclude?

<p style="color:blue"> *One option to create a map is to use the ggspatial R package, similar to Section 4.1.4 in the lecture notes:* </p>

```{r, warning=FALSE, message=FALSE, fig.align='center', out.width='70%'}
ggplot( Temperature, aes( x=Lon, y=Lat ) ) + 
  annotation_map_tile( zoom=5 ) + 
  geom_spatial_point( aes(color=MeanTemp) ) +
  scale_color_distiller( palette="Reds", trans="reverse" ) +
  labs( x="Longitude", y="Latitude", color="Mean Daily Temperature" )
```

<p style="color:blue"> *The plot suggests that stations in the north of the study area tend to see higher average temperatures than stations in the south. The map also indicates that locations closer to the sea have a lower average daily temperature. We also see that spatially close sites observe similar average temperatures.*</p>

c) Use inverse distance weighting to predict average daily temperature across north-eastern Brazil. Make sure to choose a suitable power parameter. Comment on the reliability of our estimates.

<p style="color:blue"> *We start by loading the IDW() function defined in Section 4.2.2 in the lecture notes:*</p> 

```{r}
IDW <- function( X, S, s_star, p){
  d <- sqrt( (S[,1]-s_star[1])^2 + (S[,2]-s_star[2])^2 )
  w <- d^(-p)
  if( min(d) > 0 )
    return( sum( X * w ) / sum( w ) )
  else 
    return( X[d==0] )
}
```

<p style="color:blue"> *We now perform the steps as outlined in Section 4.2.3. The first step is to define a grid and to calculate the predicted values. For the choice of $p$, we need to keep two aspects in mind: (i) the plot should look relatively smooth and (ii) the range of predicted values should be very close to the range of observed values. One value for $p$ which satisfies these criteria is $p=1.7$ (which we can find by trial-and-error): *</p> 

```{r}
lon <- seq( -48, -34, by=0.1 )
lat <- seq( -20, 0, by=0.1 )
pixels <- as.matrix( expand.grid( lon, lat ) )
Predict <- c()
coord <- cbind( Temperature$Lon, Temperature$Lat )

for( j in 1:length(pixels[,1]) )
  Predict[j] <- IDW( Temperature$MeanTemp, coord, pixels[j,], p=1.7 )
  
IDW_predict <- data.frame( "Lon"=pixels[,1], "Lat"=pixels[,2], "Pred"=Predict )
```

<p style="color:blue"> *Finally, we create the map using the same steps as in the example from the lecture notes, but we have to limit the range of the longitude and latitude as in part a):* </p>

```{r, warning=FALSE, fig.align='center', out.width='70%'}
ggplot() + theme_bw() + 
  geom_raster( data=IDW_predict, aes(x=Lon, y=Lat, fill=Pred) ) +
  scale_fill_distiller( palette="Reds", trans="reverse" ) +
  geom_sf( data=Brazil, alpha=0.0, color="white" ) +
  geom_point( data=Temperature, aes(x=Lon,y=Lat), color="white" ) +
  xlim( -48, -34 ) + ylim( -20, 0 ) +
  labs( x="Longitude", y="Latitude", fill="Daily Mean Temperature" )
```

<p style="color:blue"> *The plot supports our statement in part a) that the north and centre of the region recorded higher average temperatures than the southern half.* </p>

<p style="color:blue"> *There are two areas for which our predictions are likely to be unreliable, while the rest of predictions is probably not too bad. The first area is the sea, because the temperature dynamics will differ substantially from that on land. The second area is the left bottom corner of the map - none of the weather stations really lies close to to this area, and thus our predictions are unreliable.*</p>


### **Tutorial Question 2 - Alaskan horsehair crab landings**

In Section 4.1.3 we covered the topic of projections. The following tasks showcase one important aspect we should keep in mind when working with projections and demonstrates how we may handle it.

The data file “Crabs.csv” contains catch per unit effort (CPUE) data of commercial horsehair crab landings for various locations across the Alaskan Eastern Bering Sea for 2010-2018. CPUE is an indirect measure of the abundance of a species. We want to visualize the data using the shapefile for Alaska:

```{r}
Alaska <- read_sf( "Shapefiles/Alaska.shp" )
```

a) Create a plot of the provided shapefile. Is the WGS84 coordinate reference system being used for the plot?

<p style="color:blue">*We plot the shapefile as we have seen in the lecture:*</p>

```{r, out.width='50%', fig.align='center', fig.height=4}
ggplot( Alaska ) + geom_sf() + theme_bw() + 
  labs( x="Longitude", y="Latitude" )
```

<p style="color:blue">*The plot is not using the WGS84 coordinate reference system because the angles are not preserved and we have more of a sense of the area being located on a sphere.*</p>


We now want to explore the spatial data contained in "Crabs.csv". Run the following piece of R code

```{r, out.width='50%', fig.align='center', fig.height=4}
Crabs <- read.csv( "Crabs.csv" )
ggplot( data=Alaska ) + theme_bw() + geom_sf() + 
  geom_point( data=Crabs, aes(x=longitude, y=latitude), colour=2 ) 
```

b) Consider the data in "Crabs.csv" and discuss whether the map we produced is correct.

<p style="color:blue">*We see that there is only a single point shown in the plot. Let’s have a look at the first few data points in Crabs.csv:*</p>

```{r}
Crabs %>% slice_head( n=5 )
```

<p style="color:blue">*There is clearly something wrong with the way the points have been added to the map, because the first few data points should all lie on the map.*</p>

Let’s change the projection of the shapefile with the coord_sf() and st_crs() functions covered in Section 4.1.3:

```{r, fig.align='center', eval=FALSE}
ggplot( data=Alaska ) + theme_bw() + geom_sf() + 
  coord_sf( crs=st_crs(4326) ) + xlim(-180,-140) + 
  geom_point( data=Crabs, aes(x=longitude, y=latitude) ) 
```

c) Is this plot more realistic than that in part b)? Adapt the code such that the recorded CPUE is shown in the plot. What do you conclude from the plot?

<p style="color:blue">*We run the code and visualize CPUE using color as a visual cue:*</p>

```{r, fig.align='center', out.width='60%', fig.height=4, fig.width=7}
ggplot( data=Alaska ) + theme_bw() + geom_sf() + 
  coord_sf( crs=st_crs(4326) ) + xlim(-180,-140) + 
  geom_point( data=Crabs, aes(x=longitude, y=latitude, color=cpue) ) 
```

<p style="color:blue">*The plotted locations seem correct as we used the WGS84 coordinate reference system for both the map and the points. We conclude that Alaskan horsehair crabs are usually caught between 55°N and 60°N and slightly off the coast. There are some spots with a markedly higher CPUE, but there is no clear spatial pattern. This may be due to differences across years, or other factors such as water temperature and depth.*</p>

Instead of changing the projection of the map, let's define spatial data points using the data in "Crabs.csv":

```{r, fig.align='center', out.width='50%', fig.height=4}
Crabs_map <- Crabs %>% 
  st_as_sf( coords = c("longitude", "latitude"), crs = "WGS84" )
ggplot( data=Alaska ) + theme_bw() + geom_sf() + 
  geom_sf( data=Crabs_map, aes(color=cpue) ) +
  labs( x="Longitude", y="Latitude" )
```

d) Do the locations of the points in the created plot match with the data shown in part c)? What can we learn from the considered R code about the use of projections?

<p style="color:blue">*The locations of the plotted data points agree with these in the previous plot.*</p>

<p style="color:blue">*We have seen two methods for dealing with the case when the shapefile is not using the WGS84 projection. The first one in part c) is to transform the shapefile to WGS84 format. The second option we have seen in part d) is to define spatial data points using longitude and latitude, and to let R work it out how to combine them.*</p>


## **Homework Question - Lead concentration across Amaurot**

The local authorities in Amaurot, the capital of Utopia, have seen an alarming increase in lead concentration levels in the drinking water. They thus collected samples on lead concentration across the city. The data on the recorded lead levels and the spatial coordinates are provided in the file "Amaurot Lead.csv".

The local authorities have now approached you to help them tackle the issue. They provided you with the collected data and a shapefile of Amaurot. To hide Amaurot’s location, the latitude and longitude coordinates have been manipulated, but the provided shapes are correct. You are asked to perform the following tasks:

a) Visualize the measured lead concentrations. What do you conclude?

<p style="color:blue">*We start by loading the patient data and the shapefile*</p>

```{r}
Patients <- read.csv( "Amaurot Lead.csv" )
Amaurot <- read_sf( "Shapefiles/Amaurot.shp" )
```

<p style="color:blue">*Combining the shapefile with the data allows us to visualize the recorded lead levels:*</p>

```{r, fig.align='center', out.width='60%', fig.width=5, fig.height=4}
ggplot( Amaurot ) + theme_bw() + geom_sf() +
  geom_point( data=Patients, aes( x=Lon, y=Lat, color=Lead ) ) + 
  scale_color_distiller( palette="Reds", trans="reverse" ) +
  labs( x="Longitude", y="Latitude", color="Lead",
        title="Lead Concentration across Amaurot")
```

<p style="color:blue">*The plot reveals that the highest lead levels are recorded north and south of the centre of Amaurot, with levels of over 20 parts per million. For other areas, concentrations close to 0 parts per million were recorded.*</p>


b) Perform inverse distance weighting to predict lead levels for all points in the file "Amaurot Grid.csv"; the points form a regular grid over the whole city and there is also information in which district the point lies. Comment on the reliability of your predictions.

<p style="color:blue">*We first load the IDW() function from the lecture notes:*</p>

```{r}
IDW <- function( X, S, s_star, p){
  d <- sqrt( (S[,1]-s_star[1])^2 + (S[,2]-s_star[2])^2 )
  w <- d^(-p)
  if( min(d) > 0 )
    return( sum( X * w ) / sum( w ) )
  else 
    return( X[d==0] )
}
```

<p style="color:blue">*We make use of the provided grid as it provides information on the district each grid cell is located in. We further introduce a new variable to store the predicted lead concentrations:*</p>

```{r}
Amaurot_Grid <- read.csv("Amaurot Grid.csv")
Amaurot_Grid <- Amaurot_Grid %>% mutate( Lead = NA )
```

<p style="color:blue">*Everything is now ready for us to perform inverse distance weighting. There are a few possible choices for the power parameter, but I would say that the plot for $p=2.5$ looks quite reasonable:*</p>

```{r}
coord <- cbind( Patients$Lon, Patients$Lat )
Grid  <- cbind( Amaurot_Grid$Lon, Amaurot_Grid$Lat )

for( i in 1:length(Grid[,1]) )
  Amaurot_Grid$Lead[i] <- IDW( X=Patients$Lead, S=coord, s_star=Grid[i,], p=2.5 )
```

<p style="color:blue">*Finally, we visualize the predicted lead concentrations:*</p>

```{r, fig.align='center', out.width='60%'}
ggplot() + theme_bw() +
  geom_tile( data=Amaurot_Grid, aes(x=Lon, y=Lat, fill=Lead) ) +
  scale_fill_distiller( palette="Reds", trans="reverse" ) +
  geom_sf( data=Amaurot, alpha=0.0, color="white", linewidth=0.7 ) + 
  labs( title="Lead concentration predictions for p=2.5", 
        fill="Lead", x="Longitude", y="Latitude" )
```

<p style="color:blue">*In terms of reliability, the use of the Euclidian distance is probably not a good choice since:*</p>

* <p style="color:blue">*Drinking water is transported via water pipes, and so two spatially close households may observe very different lead concentrations.*</p> 

* <p style="color:blue">*There is probably one more or sources which explain the high lead concentration. Due to households being serviced by a network of water pipes, households up to the point lead enters the system will be fine, while others further down the network may be affected.*</p>


c) The authorities want to reduce the occurrences of lead concentrations exceeding a level of 10 parts per million. They have thus decided to deploy a team to one of the districts with the job of reducing lead levels to below this threshold for all households in that districts. Use your results in part b) to identify which district should be targeted.

<p style="color:blue">*One option is to estimate for each district the proportion of households affected by a lead concentration above 10 parts per million (this requires certain assumptions):*</p>

```{r}
Amaurot_Grid %>% 
  group_by( District ) %>%
  summarise( AreaExceedingThreshold = mean(Lead>10) ) %>%
  slice_max( AreaExceedingThreshold, n=3 )
```

<p style="color:blue">*Our results suggest that almost all of District 13 would benefit from sending the team, with District 1 being a close second (we may also want to consider the size of the districts).*</p>
